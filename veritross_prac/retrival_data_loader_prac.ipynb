{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install jsonlines, Numpy, beir\n",
    "```\n",
    "pip install jsonlines numpy beir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Triviaqa Dataset Download\n",
    "```\n",
    "wget http://nlp.cs.washington.edu/triviaqa/data/triviaqa-rc.tar.gz\n",
    "tar -xvf triviaqa-rc.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Import Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from beir.datasets.data_loader import GenericDataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Main Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrieve_eval_data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_eval_data_loader(data_name, query_file, corpus_file,qrels_file):\n",
    "\n",
    "    data_path = f\"datasets/{data_name}/\"\n",
    "    \n",
    "    print(\"=====> Loading QA Dataset\")\n",
    "    print(\"=====> Loading Pool of Documents\")\n",
    "    corpus, queries, qrels = GenericDataLoader(\n",
    "        data_folder = data_path,\\\n",
    "        corpus_file = corpus_file,\\\n",
    "        query_file = query_file,\\\n",
    "        ).load(split=qrels_file) # or split = \"train\" or \"dev\"\n",
    "    \n",
    "\n",
    "    \n",
    "    return corpus, queries, qrels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### custom_data_loaer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_data_loader(args):\n",
    "\n",
    "    if args.data_name == 'triviaqa':\n",
    "        questions = []\n",
    "        answers = []\n",
    "        with jsonlines.open(args.qa_data) as f:\n",
    "            for line in f.iter():\n",
    "                questions.append(line[\"query\"])\n",
    "                answers.append(line[\"answers\"])\n",
    "    \n",
    "        retrieval_queries = {}\n",
    "        for i in tqdm(range(len(questions)), desc=\"QA Data Preprocessing\"):\n",
    "            question = questions[i]\n",
    "            qa_id = str(args.data_name) + \"_\" + str(i)\n",
    "            retrieval_queries[qa_id] = question\n",
    "    \n",
    "        titles = []\n",
    "        texts = []\n",
    "        with jsonlines.open(args.documents_pool) as f:\n",
    "            for line in f.iter():\n",
    "                texts.append(line[\"text\"])\n",
    "                titles.append(line[\"title\"])\n",
    "    \n",
    "        retrieval_corpus = {}\n",
    "        for i in tqdm(range(len(titles)), desc= \"Documents_Pool Preprocessing\"):\n",
    "            json_obj = {}\n",
    "            json_obj[\"title\"] = titles[i]\n",
    "            json_obj[\"text\"] = texts[i]\n",
    "            retrieval_corpus[str(i)] = json_obj\n",
    "\n",
    "    return retrieval_queries, retrieval_corpus, questions, answers, titles, texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make_new_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_new_dataset(args, retrieved_doc):\n",
    "        \n",
    "        _,_, questions, answers, titles,texts = custom_data_loader(args)\n",
    "        print(\"=====> Starting Construction of Dataset\")\n",
    "\n",
    "        sorted_idxs = []\n",
    "        sorted_scores = []\n",
    "\n",
    "        for i in range(len(titles)):\n",
    "            scores_i = np.array(list(retrieved_doc['{}_{}'.format(args.data_name, i)].values()))\n",
    "            sorted_idx = np.argsort(scores_i)[::-1]\n",
    "            keys = list(retrieved_doc['{}_{}'.format(args.data_name, i)].keys())\n",
    "\n",
    "            sorted_idxs_i = []\n",
    "            sorted_scores_i = []\n",
    "            for j in range(min(len(scores_i), args.num_retrieval)):\n",
    "                sorted_idxs_i.append(int(keys[sorted_idx[j]]))\n",
    "                sorted_scores_i.append(scores_i[sorted_idx[j]])\n",
    "\n",
    "            sorted_idxs.append(sorted_idxs_i)\n",
    "            sorted_scores.append(sorted_scores_i)\n",
    "\n",
    "        res = []\n",
    "        for i in range(len(questions)):\n",
    "            new_item = {}\n",
    "            new_item['question'] = questions[i]\n",
    "            new_item['answer'] = answers[i]\n",
    "\n",
    "            ctxs = []\n",
    "            for j in range(len(sorted_idxs[i])):\n",
    "                ctx = {}\n",
    "                ctx['id'] = sorted_idxs[i][j]\n",
    "                ctx['title'] = titles[sorted_idxs[i][j]]\n",
    "                ctx['text'] = texts[sorted_idxs[i][j]]\n",
    "                ctx['score'] = sorted_scores[i][j]\n",
    "                ctxs.append(ctx)\n",
    "            new_item['contexts'] = ctxs\n",
    "            res.append(new_item)\n",
    "\n",
    "        if not os.path.exists(args.output_folder):\n",
    "            os.makedirs(args.output_folder)\n",
    "        \n",
    "        print(\"=====> All Procedure is finished!\")\n",
    "        with open(f\"{args.output_folder}/{args.data_name}/{args.retrieval_method}_retrieved_docs.doc\",'w') as writer:\n",
    "            writer.write(json.dumps(res, indent=4, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    data_name = 'triviaqa'\n",
    "    qa_data = '/content/qa/wikipedia-dev.json'  # TriviaQA QA 데이터 경로\n",
    "    documents_pool = '/content/documents_pool.json'  # 문서 풀 데이터 경로\n",
    "    output_folder = 'output_folder'\n",
    "    retrieval_method = 'retrieval_method'\n",
    "    num_retrieval = 5\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_doc = {f'triviaqa_{i}': {str(j): np.random.random() for j in range(10)} for i in range(5)}  # 예시 데이터\n",
    "\n",
    "make_new_dataset(args, retrieved_doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
